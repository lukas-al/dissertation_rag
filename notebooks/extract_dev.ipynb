{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data from the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings, VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.duckdb import DuckDBVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import glob\n",
    "import PyPDF2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata extraction & data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the excel sheet where I've manually logged all the metadata\n",
    "metadata_df = pd.read_excel(\n",
    "    r\"N:\\CECD\\10. Personal\\Lukas Alemu\\Study Repository\\99. Capstone\\dissertation_rag\\config\\data_organisation.xlsx\",\n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_path = r'N:\\CECD\\10. Personal\\Lukas Alemu\\Study Repository\\99. Capstone\\dissertation_rag\\data\\01_raw\\Agenda for the January 2020 Benchmark and Key Issues meetings.pdf'\n",
    "file_name = test_file_path.split('\\\\')[-1]\n",
    "\n",
    "# metadata = metadata_df.loc[file_name]\n",
    "# print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "problem - not all our filenames match the keys. I made some errors in copying. Maybe I can do a simple fuzzy match? Performance is not a concern here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Description': 'For 2020, survey respondents expect pay settlements to remain flat at the 2.9% reported for 2019. \\nIn contrast, respondents expect growth in total labour costs per employee to increase somewhat.  While the difference could partly reflect the impact of non-pay benefits and changes in the composition of the workforce, we would put more weight on the steer from the settlements responses for the outlook for pay growth. \\nAs in 2019, the “Ability to recruit and retain staff” and “the National Living Wage” are driving up the growth rate of total labour costs per employee in 2020.  “Brexit Uncertainty”, “Changes in profitability” and “Economic Uncertainty” continue to pull down on the change in the growth rate of total labour costs per employee. ',\n",
       " 'Type': 'Recommended reading',\n",
       " 'Date': Timestamp('2020-01-15 00:00:00'),\n",
       " 'Authors': 'Florence Hubert, Frances Hill, Louise Parreira, Alexis Tessier, Iain Duff',\n",
       " 'Topics': 'Inflation > Inflation Expectations, Business Conditions',\n",
       " 'Brands': 'Agency',\n",
       " 'Academic Research Cited?': 'No',\n",
       " 'Divisions': 'Agencies',\n",
       " 'MPC Round': 'MPC January 2020',\n",
       " 'Forecast Round': nan,\n",
       " 'Tags': nan,\n",
       " 'Related Notes': nan}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_name(name, df, min_score=0):\n",
    "    # Returns the best match from a list of names to the input name\n",
    "    max_score = -1\n",
    "    max_name = \"\"\n",
    "\n",
    "    # for idx in df.index:\n",
    "    for n in df.index.tolist():\n",
    "        score = process.extractOne(name, [n])[1]\n",
    "        if (score > min_score) & (score > max_score):\n",
    "            max_name = n\n",
    "            max_score = score\n",
    "    \n",
    "    return (max_name, max_score)\n",
    "\n",
    "file_name = 'Agencies Pay and Labour Market Survey (MPC Note - January 2020) '\n",
    "nm, _ = match_name(file_name, metadata_df)\n",
    "metadata_df.loc[nm].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works - lets wrap this in a function to work for the llamaindex boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def match_notes_metadata(file_path: str, metadata_df: pd.DataFrame):\n",
    "    \"\"\"Match the metadata using the file name and the manual extracts\n",
    "    I pasted into the 'data organisation' spreadsheet. \n",
    "\n",
    "    Args:\n",
    "        file_path (str): absolute file path to the pdf to match\n",
    "        metadata_df (pd.DataFrame): dataframe of the data organisation spreadsheet\n",
    "\n",
    "    Returns:\n",
    "        dict: dictionary containing the matched metadata\n",
    "    \"\"\"\n",
    "    file_name = file_path.split('\\\\')[-1]\n",
    "    idx_nm, _ = match_name(file_name, metadata_df)\n",
    "    matched_metadata = metadata_df.loc[idx_nm].to_dict()\n",
    "\n",
    "    return matched_metadata\n",
    "\n",
    "def get_random_metadata(file_path: str):\n",
    "    \"\"\"Dummy function to demonstrate how we could extract extra\n",
    "    metadata from the text. We're going to need to make this \n",
    "    much more sophisticated.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): absolute file path to the pdf\n",
    "\n",
    "    Returns:\n",
    "        dict: collection of random metadata\n",
    "    \"\"\"\n",
    "    random_metadata = {}\n",
    "    # Read the document and extract metadata as a dictionary\n",
    "    with open(file_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        # Get the number of characters in the pdf\n",
    "        text = ''\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        random_metadata['num_characters'] = len(text)\n",
    "\n",
    "        # Get the number of words in the pdf\n",
    "        words = text.split()\n",
    "        random_metadata['num_words'] = len(words)\n",
    "\n",
    "        # Get the most common 5 words in the pdf\n",
    "        word_counts = Counter(words)\n",
    "        random_metadata['most_common_words'] = dict(word_counts.most_common(5))\n",
    "\n",
    "    return random_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a function to extract links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata(file_path: str):\n",
    "    \"\"\"Gather all the metadata into one spot\n",
    "\n",
    "    Args:\n",
    "        file_path (str): absolute file path to pdf \n",
    "\n",
    "    Returns:\n",
    "        dict: collection of our metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    matched_metadata = match_notes_metadata(file_path, metadata_df)\n",
    "    random_metadata = get_random_metadata(file_path)\n",
    "\n",
    "    return {**matched_metadata, **random_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the documents\n",
    "path_to_docs = pathlib.PurePosixPath(r\"N:\\CECD\\10. Personal\\Lukas Alemu\\Study Repository\\99. Capstone\\dissertation_rag\\data\\01_raw\")\n",
    "documents = SimpleDirectoryReader(path_to_docs, file_metadata=get_metadata).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'page_label': '1',\n",
       " 'file_name': 'Agencies Pay and Labour Market Survey (MPC Note - January 2020).pdf',\n",
       " 'Description': 'For 2020, survey respondents expect pay settlements to remain flat at the 2.9% reported for 2019. \\nIn contrast, respondents expect growth in total labour costs per employee to increase somewhat.  While the difference could partly reflect the impact of non-pay benefits and changes in the composition of the workforce, we would put more weight on the steer from the settlements responses for the outlook for pay growth. \\nAs in 2019, the “Ability to recruit and retain staff” and “the National Living Wage” are driving up the growth rate of total labour costs per employee in 2020.  “Brexit Uncertainty”, “Changes in profitability” and “Economic Uncertainty” continue to pull down on the change in the growth rate of total labour costs per employee. ',\n",
       " 'Type': 'Recommended reading',\n",
       " 'Date': Timestamp('2020-01-15 00:00:00'),\n",
       " 'Authors': 'Florence Hubert, Frances Hill, Louise Parreira, Alexis Tessier, Iain Duff',\n",
       " 'Topics': 'Inflation > Inflation Expectations, Business Conditions',\n",
       " 'Brands': 'Agency',\n",
       " 'Academic Research Cited?': 'No',\n",
       " 'Divisions': 'Agencies',\n",
       " 'MPC Round': 'MPC January 2020',\n",
       " 'Forecast Round': nan,\n",
       " 'Tags': nan,\n",
       " 'Related Notes': nan,\n",
       " 'num_characters': 12051,\n",
       " 'num_words': 1893,\n",
       " 'most_common_words': {'in': 64, 'to': 59, 'of': 59, 'the': 57, 'growth': 28}}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OTHER STUFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist the data into a db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the vector store\n",
    "path_to_db = pathlib.PurePosixPath(r\"//Users/lukasalemu/Documents/00. Bank of England/00. Degree/Dissertation/structured-rag/data/02_processed\")\n",
    "vector_store = DuckDBVectorStore(\"pg.duckdb\", persist_dir=str(path_to_db))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the embedd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the db\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the boilerplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure things to point in the right place\n",
    "Settings.embed_model = embed_model\n",
    "Settings.chunk_size = 512\n",
    "\n",
    "storage_settings = StorageContext.from_defaults(\n",
    "    vector_store=vector_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the index and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the index\n",
    "index = VectorStoreIndex.from_documents(documents, storage_context=storage_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the index from the vector db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vector store from local\n",
    "vector_store = DuckDBVectorStore.from_local(str(path_to_db/\"pg.duckdb\"))\n",
    "index = VectorStoreIndex.from_vector_store(vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can retrieve similar documents to a given query\n",
    "query_text = \"What is the forecast\"\n",
    "\n",
    "results = index.as_retriever().retrieve(query_text)\n",
    "\n",
    "print(len(results))\n",
    "print(results[0].text)\n",
    "print(results[0].metadata)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Add the project root directory to the system path\n",
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "\n",
    "from src.etl.etl_funcs import load_documents\n",
    "from src.etl.embedding_funcs import embed_index\n",
    "from src.algorithms import v0, v1\n",
    "from src.processing import graph_construction, distance_metrics\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding Documents: 100%|██████████| 197/197 [00:06<00:00, 29.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Load the document index\n",
    "document_index = load_documents()\n",
    "\n",
    "# Embed the document index\n",
    "embedded_index = embed_index(document_index)\n",
    "\n",
    "sub_index = embedded_index[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single process timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:05<00:00, 34.03it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "doc_distance_vectors = {}\n",
    "\n",
    "retriever = v0.V0Retriever()\n",
    "\n",
    "# For each document\n",
    "for doc in tqdm.tqdm(embedded_index):\n",
    "    for other_doc in embedded_index:\n",
    "        # Calculate all the distance vectors for every other doc and nest them into a dictionar\n",
    "        doc_distance_vectors[doc.id_] = {\n",
    "            other_doc.id_: retriever.calculate_distance(doc, other_doc)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:02<00:00, 19.40it/s]\n"
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "doc_distance_vectors = {}\n",
    "\n",
    "retriever = v1.V1Retriever()\n",
    "\n",
    "# For each document\n",
    "for doc in tqdm.tqdm(sub_index):\n",
    "    for other_doc in sub_index:\n",
    "        # Calculate all the distance vectors for every other doc and nest them into a dictionar\n",
    "        doc_distance_vectors[doc.id_] = {\n",
    "            other_doc.id_: retriever.calculate_distance(doc, other_doc)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi process timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk 1026c639-9265-4ddb-a0cf-2a7e91737602: 100%|██████████| 22/22 [00:01<00:00, 16.81it/s]\n",
      "Processing chunk e983f9b7-10a1-46b4-a460-e912349e0ade: 100%|██████████| 22/22 [00:00<00:00, 23.48it/s]\n",
      "Processing chunk 54c40cb7-ffcf-4bab-99ab-4c3ea548c7c8: 100%|██████████| 22/22 [00:00<00:00, 27.22it/s]\n",
      "Processing chunk d4e5638e-41a0-44a5-92ed-a4c2521877ef: 100%|██████████| 22/22 [00:00<00:00, 35.45it/s]\n",
      "Processing chunk c1fee0bc-c189-4faa-a845-927623fb517d: 100%|██████████| 22/22 [00:00<00:00, 34.89it/s]\n",
      "Processing chunk ee0bfddf-e01a-4c96-bbf5-9caa7f73f531: 100%|██████████| 22/22 [00:00<00:00, 35.05it/s]\n",
      "Processing chunk 6d3ed7e9-5c9b-40d7-a5ae-16106ceeb90a: 100%|██████████| 22/22 [00:00<00:00, 36.58it/s]\n",
      "Processing chunk 0189064d-82b4-48b4-ab30-0cca6a9d3f22: 100%|██████████| 22/22 [00:00<00:00, 36.60it/s]\n",
      "Processing chunk f344b0e5-4f18-4618-8d7b-b5c6310edf66: 100%|██████████| 21/21 [00:00<00:00, 38.45it/s]\n"
     ]
    }
   ],
   "source": [
    "adj_matrix = graph_construction.construct_adjacency_dict_parallel(\n",
    "    embedded_index=embedded_index,\n",
    "    retrieval_class=v0.V0Retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunk e983f9b7-10a1-46b4-a460-e912349e0ade: 100%|██████████| 6/6 [00:00<00:00, 17.18it/s]\n",
      "Processing chunk d4e5638e-41a0-44a5-92ed-a4c2521877ef: 100%|██████████| 6/6 [00:00<00:00, 13.81it/s]\n",
      "Processing chunk 54c40cb7-ffcf-4bab-99ab-4c3ea548c7c8: 100%|██████████| 6/6 [00:00<00:00, 13.76it/s]\n",
      "Processing chunk 1026c639-9265-4ddb-a0cf-2a7e91737602: 100%|██████████| 6/6 [00:00<00:00,  8.46it/s]\n",
      "Processing chunk c1fee0bc-c189-4faa-a845-927623fb517d: 100%|██████████| 6/6 [00:00<00:00, 10.76it/s]\n",
      "Processing chunk 6d3ed7e9-5c9b-40d7-a5ae-16106ceeb90a: 100%|██████████| 5/5 [00:00<00:00, 15.62it/s]\n",
      "Processing chunk ee0bfddf-e01a-4c96-bbf5-9caa7f73f531: 100%|██████████| 5/5 [00:00<00:00, 16.10it/s]\n",
      "Processing chunk f344b0e5-4f18-4618-8d7b-b5c6310edf66: 100%|██████████| 5/5 [00:00<00:00, 19.59it/s]\n",
      "Processing chunk 0189064d-82b4-48b4-ab30-0cca6a9d3f22: 100%|██████████| 5/5 [00:00<00:00, 19.54it/s]\n"
     ]
    }
   ],
   "source": [
    "adj_matrix = graph_construction.construct_adjacency_dict_parallel(\n",
    "    embedded_index=sub_index,\n",
    "    retrieval_class=v1.V1Retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution was to move the embedding logic all to the initial call. Uses the pre-built parallelism of the huggingface library much more effectively.\n",
    "\n",
    "The rest of the function calls are so quick and use so little overhead we don't need to multiprocess really."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dissertation_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

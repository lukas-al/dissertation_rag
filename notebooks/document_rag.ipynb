{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaffold the user-based application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from datetime import date\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Add the project root directory to the system path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from StructuredRag.evaluation import graph_scoring\n",
    "from StructuredRag.processing import graph_construction\n",
    "from StructuredRag.algorithms import v0, v1\n",
    "from StructuredRag.processing import distance_metrics\n",
    "from StructuredRag.etl import embedding_funcs, etl_funcs\n",
    "\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing LM load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 3.0.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer(r\"C:\\Users\\335257\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2\\snapshots\\cbce8a8c7380b8bc926ac6d6425442c393b66d10\")\n",
    "model = SentenceTransformer(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.704995155334473"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"Homer is a Simpsons character\"\n",
    "q2 = \"Shakespeare is a great poet\"\n",
    "\n",
    "\n",
    "emb1 = model.encode(q1)\n",
    "emb2 = model.encode(q2)\n",
    "\n",
    "float(util.dot_score(emb1, emb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading item: embedded_index\n",
      "Loading item: edge_thresh\n",
      "Loading item: adj_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from StructuredRag.algorithms.inquirer import StructRAGInquirer\n",
    "\n",
    "inquirer = StructRAGInquirer(\n",
    "    path_to_experiment='/Users/lukasalemu/Documents/00. Bank of England/00. Degree/Dissertation/structured-rag/results/v0/2024-05-27',\n",
    "    llm_name='google/flan-t5-large',\n",
    "    llm_max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = inquirer.run_inquirer(\n",
    "    query='How will climate change affect the economy?',\n",
    "    source_document_name='MPR November 2023.pdf',\n",
    "    k_context=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.24579640986078943\n",
      "0.25843880294410515\n"
     ]
    }
   ],
   "source": [
    "for doc in res['input_documents']:\n",
    "    print(doc.metadata[\"doc_difference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Physical impacts, for example extreme weather events and rising temperatures, can lead to disruptions in both output and inflation. Likewise, the transition to a low-carbon economy can impact activity through changes in policies, preferences, and technology . These channels will have resulting impacts for trends in labour productivity.',\n",
       " 'input_documents': [Document(page_content='Climate change will affect the macroeconomy through a number of channels ( Angeli et al (2022)).\\nPhysical impacts, for example extreme weather events and rising temperatures, can lead to\\ndisruptions in both output and inflation. Likewise, the transition to a low-carbon economy can impact\\nactivity through changes in policies, preferences, and technology . These channels will have resulting\\nimpacts for trends in labour productivity.\\nAround a third of DMP Survey respondents reported that climate change has resulted in an increase\\nin their expenditure on capital over the past three years. Those who expected to increase their\\nclimate-related investments over the next three years are most likely to do so by investing in\\nswitching to green energy sources or production methods that use energy more ef ficiently (Chart\\n3.7).\\nRecent scenarios released by the Network for Greening the Financial System (NGFS) (2023)\\nmodel, among other things, the impact on trend labour productivity from chronic physical and\\ntransition risks under existing climate policies versus those that would achieve net-zero emissions by\\n2050. The NGFS scenarios suggest that, compared to existing climate policies, net-zero consistent\\npolicies could drag on trend productivity growth in the medium term, but boost it in the long run.Chart 3.6: Businesses that have invested in AI expect productivity gains within a few years\\nFirm expectations of the speed of productivity gains from AI investments (a)\\nSource: Bank’s Agents.\\n(a) Chart shows responses to the question: ‘How quickly do most of the productivity gains from the new AI investments accrue to your\\nUK business?’ from respondents who had answered ‘Yes’ to the question: ‘In the past 12 months have you made any new significant or\\ntransformative AI investments in your UK business?’.\\nIncreases in investment in order to try and achieve net-zero emissions by 2050 may spur an\\nincrease in long-run trend productivity growth.\\nPage 81\\nBank of England', metadata={'doc_num': 3, 'doc_description': 'The 2024 MPR from the Bank of England for the month of February. Contains the forecasts, projections, etc.', 'doc_date': '2024-02-04 00:00:00', 'doc_difference': 0, 'title': 'monetary policy report february 2024.pdf'}),\n",
       "  Document(page_content='have previously\\nbeen based on the Labour Force Survey (LFS). A decline in response rates has resulted\\nBank of England  \\nPage 15', metadata={'doc_num': 1, 'doc_description': 'Our quarterly Monetary Policy Report sets out the economic analysis and inflation projections that the Monetary Policy Committee uses to make its interest rate decisions.', 'doc_date': '2023-02-11 00:00:00', 'doc_difference': 0.24579640986078943, 'title': 'MPR November 2023.pdf'}),\n",
       "  Document(page_content='Lending growth to households remains weak, with the 12-month rate of net lending to households\\nfalling to 1% in December, the lowest since 2013. Within this, mortgage lending growth remained\\nsubdued, with the annual rate falling to zero. Weak mortgage lending has been driven by low gross\\nlending, with total repayment volumes broadly in line with pre-pandemic averages. Meanwhile,\\nannual growth in consumer credit continued to be robust at 8.5% in December .\\nLenders reporting to the CCS expected demand for both mortgage lending and consumer credit to\\nincrease in the three months to February, with these expectations balances stronger than in recent\\nsurveys. Consistent with this, mortgage approvals for house purchase have increased slightly ,\\nalthough they remain lower than their 2010–19 average, suggesting mortgage lending will continue to\\nbe subdued in the near term.\\nThe annual growth rate of net lending to large companies remained weak at 0.7% in the latest data\\nfor December, reflecting in part subdued credit demand. Lenders in the CCS reported that demand\\nfor corporate lending had stabilised at a low level in 2023 Q4, following a trend of falling demand over\\nprevious quarters. The annual growth rate of lending to SMEs remained broadly unchanged at\\naround -5%, largely reflecting continued repayment of borrowing under Covid loan schemes.\\nThe annual growth rate of sterling broad money (M4ex) rose to -0.3% in December from a low of\\n-4.2% in September, while the growth rate of M4 excluding other financial corporations was more\\nstable at -0.2% (Chart 2.8). The greater volatility in the headline measure largely reflects swings in\\nthe broad money holding of non-intermediate other financial corporations last year , associated with\\ndevelopments at liability-driven investment funds. Both measures of money growth remain well below\\ntheir historical averages. Several factors have contributed to the weakness in aggregate broad\\nmoney growth, including a reduction in banks’ net lending, particularly net lending to other financial\\ninstitutions, and the effects of quantitative tightening, which tend to reduce the level of bank deposits.Growth in lending to both households and businesses has continued to be low , but with\\nsome signs of stabilisation.\\nMoney growth has remained weak…\\nPage 39\\nBank of England', metadata={'doc_num': 2, 'doc_description': 'The 2024 MPR from the Bank of England for the month of February. Contains the forecasts, projections, etc.', 'doc_date': '2024-02-04 00:00:00', 'doc_difference': 0.25843880294410515, 'title': 'monetary policy report february 2024.pdf'})]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: v0\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "     || Run: 2024-05-25\n",
      "Experiment: v1\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v3\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v4\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v5\n",
      "     || Run: 2024-05-14\n"
     ]
    }
   ],
   "source": [
    "# Select the runs you want to load\n",
    "for experiment in sorted(os.listdir('../results')):\n",
    "    print('Experiment:', experiment)\n",
    "    for run in sorted(os.listdir('../results/' + experiment)):\n",
    "        print(\"     || Run:\", run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading item: embedded_index\n",
      "Loading item: edge_thresh\n",
      "Loading item: adj_matrix\n"
     ]
    }
   ],
   "source": [
    "run_path = 'v0/2024-05-25'\n",
    "\n",
    "data = {}\n",
    "# Read the data for the specified experiment\n",
    "for item in os.listdir('../results/' + run_path):\n",
    "    print('Loading item:', item.split('.')[0])\n",
    "    \n",
    "    with open('../results/' + run_path + '/' + item, 'rb') as f:\n",
    "        data[item.split('.')[0]] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the query and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'monetary policy report february 2024.pdf'\n",
      "'.gitkeep'\n",
      "'MPR November 2023.pdf'\n"
     ]
    }
   ],
   "source": [
    "# User selects one of the documents\n",
    "for doc in os.listdir(\"../data/01_raw/\"):\n",
    "    pprint(doc)\n",
    "\n",
    "selected_doc = 'monetary policy report february 2024.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# User's query\n",
    "# query = 'What is the relationship between unemployment and inflation?'\n",
    "query = 'What are the key risks to the economy'\n",
    "\n",
    "# Embed the query\n",
    "embedded_query = embedding_funcs.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar chunk of the document\n",
    "sim_scores = {}\n",
    "for doc in data['embedded_index']:\n",
    "    if doc.metadata[\"file_name\"].split(\"/\")[-1] == selected_doc:\n",
    "        sim_scores[doc.id_] = float(util.dot_score(embedded_query, doc.embedding))\n",
    "        # sim_scores[doc.id_] = cosine_similarity(embedded_query.reshape(1, -1), np.array(doc.embedding).reshape(1, -1))[0][0]\n",
    "\n",
    "# Sort the chunks\n",
    "doc_similarity = dict(sorted(sim_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "most_similar_doc_id = list(doc_similarity.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect the performance of the embedding search\n",
    "# for doc in data['embedded_index']:\n",
    "#     if doc.id_ == most_similar_doc_id:\n",
    "#         print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through the graph to find the most similar nodes\n",
    "graph = graph_construction.construct_graph_from_adj_dict(data['adj_matrix'], data['edge_thresh'], data['embedded_index'])\n",
    "\n",
    "node_paths = nx.single_source_dijkstra(G=graph, source=most_similar_doc_id, weight='weight')\n",
    "\n",
    "k = 5\n",
    "nearest_node_ids = list(node_paths[0].items())[:k]\n",
    "# nearest_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('28366e53-34b9-4492-a96f-c780adaa8911', 0),\n",
       " ('b3b0668a-275d-425d-b5ee-a7f3921e1fa8', 0.24459935597241614),\n",
       " ('f6245d2a-e66c-4346-a7d3-5a3fc098c453', 0.28790442749836603),\n",
       " ('6607baa7-b597-41c1-81c9-8c229f0cb397', 0.2928786271924973),\n",
       " ('6e008375-ac01-4a8d-b71e-30a17715d2b2', 0.3375807858294453)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the info from the nodes\n",
    "nearest_docs = []\n",
    "for doc in data['embedded_index']:\n",
    "    for node in nearest_node_ids:\n",
    "        if node[0] == doc.id_:\n",
    "            nearest_docs.append((doc, node[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_docs[3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model_name = \"google/flan-t5-large\"\n",
    "llm_temperature = 0.0\n",
    "llm_max_tokens = 512\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=generative_model_name, \n",
    "    task=\"text2text-generation\", \n",
    "    model_kwargs={\n",
    "        # \"temperature\": llm_temperature, \n",
    "        \"max_length\": llm_max_tokens,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the documents into a langchain document class\n",
    "top_matches = [\n",
    "    Document(\n",
    "        page_content=doc.text,\n",
    "        metadata={\n",
    "            'doc_num': i + 1,\n",
    "            # **doc.metadata,\n",
    "        }\n",
    "    )\n",
    "    for i, doc in enumerate(nearest_docs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List, Optional\n",
    "\n",
    "\n",
    "# class LlmResponse(BaseModel):\n",
    "#     answer_provided: bool = Field(\n",
    "#         description=\"\"\"True if enough information is provided in the context to answer\n",
    "#         the question, False otherwise.\"\"\"\n",
    "#     )\n",
    "#     most_likely_answer: Optional[str] = Field(\n",
    "#         description=\"\"\"Answer to the question, quoting or only minimally rephrasing\n",
    "#         the provided text. Empty if answer_provided=False.\"\"\"\n",
    "#     )\n",
    "#     highlighting1: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the first context document,\n",
    "#         that are most relevant to the question and should therefore be highlighted\n",
    "#         within the context.\"\"\"\n",
    "#     )\n",
    "#     highlighting2: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the second context document,\n",
    "#         that are most relevant to the question and should therefore be highlighted\n",
    "#         within the context.\"\"\"\n",
    "#     )\n",
    "#     highlighting3: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the third and any further\n",
    "#         context document, that are most relevant to the question and should therefore\n",
    "#         be highlighted within the context.\n",
    "#         Empty if the number of context documents is smaller.\"\"\"\n",
    "#     )\n",
    "#     reasoning: Optional[str] = Field(\n",
    "#         description=\"\"\"Step by step reasoning why an answer has been selected or could\n",
    "#         not be provided. Reasoning how highlighted keywords relate to the question.\"\"\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "_core_prompt = \"\"\"\n",
    "==Background==\n",
    "You are an AI assistant with a focus on helping to answer economists' search questions\n",
    "over particular documents. Your responses should be based only\n",
    "on information provided within the query. It is important to maintain impartiality\n",
    "and non-partisanship. If you are unable to answer a question based on the given\n",
    "instructions, please indicate so. Your responses should be concise and professional,\n",
    "using British English.\n",
    "Consider the current date, {current_datetime}, when providing responses related to time. \n",
    "\"\"\"\n",
    "\n",
    "_extractive_prompt = \"\"\"\n",
    "==TASK==\n",
    "Your task is to extract and write an answer for the question based on the provided\n",
    "contexts. Make sure to quote a part of the provided context closely. If the question\n",
    "cannot be answered from the information in the context, please do not provide an answer.\n",
    "If the context is not related to the question, please do not provide an answer.\n",
    "Most importantly, even if no answer is provided, find one to three short phrases\n",
    "or keywords in each context that are most relevant to the question, and return them\n",
    "separately as exact quotes (using the exact verbatim text and punctuation).\n",
    "Explain your reasoning.\n",
    "\n",
    "Question: {question}\n",
    "Contexts: {summaries}\n",
    "\"\"\"\n",
    "\n",
    "# parser = PydanticOutputParser(pydantic_object=LlmResponse)\n",
    "\n",
    "EXTRACTIVE_PROMPT_PYDANTIC = PromptTemplate.from_template(\n",
    "    template=_core_prompt\n",
    "    + _extractive_prompt,\n",
    "    # + \"\\n\\n ==RESPONSE FORMAT==\\n{format_instructions}\"\n",
    "    # + \"\\n\\n ==JSON RESPONSE ==\\n\",\n",
    "    partial_variables={\n",
    "        \"current_datetime\": str(date.today()),\n",
    "        # \"format_instructions\": parser.get_format_instructions(),\n",
    "    },\n",
    ")\n",
    "\n",
    "_stuff_document_template = (\n",
    "    \"<Doc{doc_num} >{page_content}</Doc{doc_num}>\"\n",
    ")\n",
    "\n",
    "STUFF_DOCUMENT_PROMPT = PromptTemplate.from_template(_stuff_document_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff the documents into the model\n",
    "chain = load_qa_with_sources_chain(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=EXTRACTIVE_PROMPT_PYDANTIC,\n",
    "    document_prompt=STUFF_DOCUMENT_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2698 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"input_documents\": top_matches, \"question\": query},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'There are risks in both directions around the central projections for domestic spending and GDP , including those related to the transmission of monetary policy. In particular, there is uncertainty around the collateral and precautionary savings channels through which house prices af fect consumer spending, and around the extent to which the full effects of interest rates on business.'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

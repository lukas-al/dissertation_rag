{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaffold the user-based application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from datetime import date\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Add the project root directory to the system path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from StructuredRag.evaluation import graph_scoring\n",
    "from StructuredRag.processing import graph_construction\n",
    "from StructuredRag.algorithms import v0, v1\n",
    "from StructuredRag.processing import distance_metrics\n",
    "from StructuredRag.etl import embedding_funcs, etl_funcs\n",
    "\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing LM load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 3.0.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# model = SentenceTransformer(r\"C:\\Users\\335257\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2\\snapshots\\cbce8a8c7380b8bc926ac6d6425442c393b66d10\")\n",
    "model = SentenceTransformer(\"sentence-transformers/multi-qa-mpnet-base-dot-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.704995155334473"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"Homer is a Simpsons character\"\n",
    "q2 = \"Shakespeare is a great poet\"\n",
    "\n",
    "\n",
    "emb1 = model.encode(q1)\n",
    "emb2 = model.encode(q2)\n",
    "\n",
    "float(util.dot_score(emb1, emb2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading item: embedded_index\n",
      "Loading item: edge_thresh\n",
      "Loading item: adj_matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from StructuredRag.algorithms.inquirer import StructRAGInquirer\n",
    "\n",
    "inquirer = StructRAGInquirer(\n",
    "    path_to_experiment='/Users/lukasalemu/Documents/00. Bank of England/00. Degree/Dissertation/structured-rag/results/v0/2024-05-27',\n",
    "    llm_name='google/flan-t5-large',\n",
    "    llm_max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1103 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = inquirer.run_inquirer(\n",
    "    query='How will climate change affect the economy?',\n",
    "    source_document_name='MPR November 2023.pdf',\n",
    "    k_context=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.24579640986078943\n",
      "0.25843880294410515\n"
     ]
    }
   ],
   "source": [
    "for doc in res['input_documents']:\n",
    "    print(doc.metadata[\"doc_difference\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mres\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: v0\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "     || Run: 2024-05-25\n",
      "Experiment: v1\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v3\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v4\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v5\n",
      "     || Run: 2024-05-14\n"
     ]
    }
   ],
   "source": [
    "# Select the runs you want to load\n",
    "for experiment in sorted(os.listdir('../results')):\n",
    "    print('Experiment:', experiment)\n",
    "    for run in sorted(os.listdir('../results/' + experiment)):\n",
    "        print(\"     || Run:\", run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading item: embedded_index\n",
      "Loading item: edge_thresh\n",
      "Loading item: adj_matrix\n"
     ]
    }
   ],
   "source": [
    "run_path = 'v0/2024-05-25'\n",
    "\n",
    "data = {}\n",
    "# Read the data for the specified experiment\n",
    "for item in os.listdir('../results/' + run_path):\n",
    "    print('Loading item:', item.split('.')[0])\n",
    "    \n",
    "    with open('../results/' + run_path + '/' + item, 'rb') as f:\n",
    "        data[item.split('.')[0]] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the query and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'monetary policy report february 2024.pdf'\n",
      "'.gitkeep'\n",
      "'MPR November 2023.pdf'\n"
     ]
    }
   ],
   "source": [
    "# User selects one of the documents\n",
    "for doc in os.listdir(\"../data/01_raw/\"):\n",
    "    pprint(doc)\n",
    "\n",
    "selected_doc = 'monetary policy report february 2024.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# User's query\n",
    "# query = 'What is the relationship between unemployment and inflation?'\n",
    "query = 'What are the key risks to the economy'\n",
    "\n",
    "# Embed the query\n",
    "embedded_query = embedding_funcs.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar chunk of the document\n",
    "sim_scores = {}\n",
    "for doc in data['embedded_index']:\n",
    "    if doc.metadata[\"file_name\"].split(\"/\")[-1] == selected_doc:\n",
    "        sim_scores[doc.id_] = float(util.dot_score(embedded_query, doc.embedding))\n",
    "        # sim_scores[doc.id_] = cosine_similarity(embedded_query.reshape(1, -1), np.array(doc.embedding).reshape(1, -1))[0][0]\n",
    "\n",
    "# Sort the chunks\n",
    "doc_similarity = dict(sorted(sim_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "most_similar_doc_id = list(doc_similarity.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect the performance of the embedding search\n",
    "# for doc in data['embedded_index']:\n",
    "#     if doc.id_ == most_similar_doc_id:\n",
    "#         print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through the graph to find the most similar nodes\n",
    "graph = graph_construction.construct_graph_from_adj_dict(data['adj_matrix'], data['edge_thresh'], data['embedded_index'])\n",
    "\n",
    "node_paths = nx.single_source_dijkstra(G=graph, source=most_similar_doc_id, weight='weight')\n",
    "\n",
    "k = 5\n",
    "nearest_node_ids = list(node_paths[0].items())[:k]\n",
    "# nearest_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('28366e53-34b9-4492-a96f-c780adaa8911', 0),\n",
       " ('b3b0668a-275d-425d-b5ee-a7f3921e1fa8', 0.24459935597241614),\n",
       " ('f6245d2a-e66c-4346-a7d3-5a3fc098c453', 0.28790442749836603),\n",
       " ('6607baa7-b597-41c1-81c9-8c229f0cb397', 0.2928786271924973),\n",
       " ('6e008375-ac01-4a8d-b71e-30a17715d2b2', 0.3375807858294453)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the info from the nodes\n",
    "nearest_docs = []\n",
    "for doc in data['embedded_index']:\n",
    "    for node in nearest_node_ids:\n",
    "        if node[0] == doc.id_:\n",
    "            nearest_docs.append((doc, node[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_docs[3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model_name = \"google/flan-t5-large\"\n",
    "llm_temperature = 0.0\n",
    "llm_max_tokens = 512\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=generative_model_name, \n",
    "    task=\"text2text-generation\", \n",
    "    model_kwargs={\n",
    "        # \"temperature\": llm_temperature, \n",
    "        \"max_length\": llm_max_tokens,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the documents into a langchain document class\n",
    "top_matches = [\n",
    "    Document(\n",
    "        page_content=doc.text,\n",
    "        metadata={\n",
    "            'doc_num': i + 1,\n",
    "            # **doc.metadata,\n",
    "        }\n",
    "    )\n",
    "    for i, doc in enumerate(nearest_docs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List, Optional\n",
    "\n",
    "\n",
    "# class LlmResponse(BaseModel):\n",
    "#     answer_provided: bool = Field(\n",
    "#         description=\"\"\"True if enough information is provided in the context to answer\n",
    "#         the question, False otherwise.\"\"\"\n",
    "#     )\n",
    "#     most_likely_answer: Optional[str] = Field(\n",
    "#         description=\"\"\"Answer to the question, quoting or only minimally rephrasing\n",
    "#         the provided text. Empty if answer_provided=False.\"\"\"\n",
    "#     )\n",
    "#     highlighting1: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the first context document,\n",
    "#         that are most relevant to the question and should therefore be highlighted\n",
    "#         within the context.\"\"\"\n",
    "#     )\n",
    "#     highlighting2: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the second context document,\n",
    "#         that are most relevant to the question and should therefore be highlighted\n",
    "#         within the context.\"\"\"\n",
    "#     )\n",
    "#     highlighting3: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the third and any further\n",
    "#         context document, that are most relevant to the question and should therefore\n",
    "#         be highlighted within the context.\n",
    "#         Empty if the number of context documents is smaller.\"\"\"\n",
    "#     )\n",
    "#     reasoning: Optional[str] = Field(\n",
    "#         description=\"\"\"Step by step reasoning why an answer has been selected or could\n",
    "#         not be provided. Reasoning how highlighted keywords relate to the question.\"\"\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "_core_prompt = \"\"\"\n",
    "==Background==\n",
    "You are an AI assistant with a focus on helping to answer economists' search questions\n",
    "over particular documents. Your responses should be based only\n",
    "on information provided within the query. It is important to maintain impartiality\n",
    "and non-partisanship. If you are unable to answer a question based on the given\n",
    "instructions, please indicate so. Your responses should be concise and professional,\n",
    "using British English.\n",
    "Consider the current date, {current_datetime}, when providing responses related to time. \n",
    "\"\"\"\n",
    "\n",
    "_extractive_prompt = \"\"\"\n",
    "==TASK==\n",
    "Your task is to extract and write an answer for the question based on the provided\n",
    "contexts. Make sure to quote a part of the provided context closely. If the question\n",
    "cannot be answered from the information in the context, please do not provide an answer.\n",
    "If the context is not related to the question, please do not provide an answer.\n",
    "Most importantly, even if no answer is provided, find one to three short phrases\n",
    "or keywords in each context that are most relevant to the question, and return them\n",
    "separately as exact quotes (using the exact verbatim text and punctuation).\n",
    "Explain your reasoning.\n",
    "\n",
    "Question: {question}\n",
    "Contexts: {summaries}\n",
    "\"\"\"\n",
    "\n",
    "# parser = PydanticOutputParser(pydantic_object=LlmResponse)\n",
    "\n",
    "EXTRACTIVE_PROMPT_PYDANTIC = PromptTemplate.from_template(\n",
    "    template=_core_prompt\n",
    "    + _extractive_prompt,\n",
    "    # + \"\\n\\n ==RESPONSE FORMAT==\\n{format_instructions}\"\n",
    "    # + \"\\n\\n ==JSON RESPONSE ==\\n\",\n",
    "    partial_variables={\n",
    "        \"current_datetime\": str(date.today()),\n",
    "        # \"format_instructions\": parser.get_format_instructions(),\n",
    "    },\n",
    ")\n",
    "\n",
    "_stuff_document_template = (\n",
    "    \"<Doc{doc_num} >{page_content}</Doc{doc_num}>\"\n",
    ")\n",
    "\n",
    "STUFF_DOCUMENT_PROMPT = PromptTemplate.from_template(_stuff_document_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff the documents into the model\n",
    "chain = load_qa_with_sources_chain(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=EXTRACTIVE_PROMPT_PYDANTIC,\n",
    "    document_prompt=STUFF_DOCUMENT_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2698 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"input_documents\": top_matches, \"question\": query},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'There are risks in both directions around the central projections for domestic spending and GDP , including those related to the transmission of monetary policy. In particular, there is uncertainty around the collateral and precautionary savings channels through which house prices af fect consumer spending, and around the extent to which the full effects of interest rates on business.'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

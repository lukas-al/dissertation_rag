{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaffold the user-based application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import networkx as nx\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "from datetime import date\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# Add the project root directory to the system path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from StructuredRag.evaluation import graph_scoring\n",
    "from StructuredRag.processing import graph_construction\n",
    "from StructuredRag.algorithms import v0, v1\n",
    "from StructuredRag.processing import distance_metrics\n",
    "from StructuredRag.etl import embedding_funcs, etl_funcs\n",
    "\n",
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "\n",
    "from langchain_community.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out performance improvements\n",
    "1. Better embedding model\n",
    "2. Document re-ranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\335257\\.cache\\huggingface\\hub\\models--BAAI--bge-large-en-v1.5. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# install the new sentence transformer model...\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"BAAI/bge-large-en-v1.5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = [\n",
    "    \"\"\"The Bank of England’s Monetary Policy Committee (MPC) sets monetary policy to meet\n",
    "the 2% inflation target, and in a way that helps to sustain growth and employment. At its\n",
    "meeting ending on 29 January 2020, the MPC voted by a majority of 7–2 to maintain\n",
    "Bank Rate at 0.75%. The Committee voted unanimously to maintain the stock of sterling\n",
    "non-financial investment-grade corporate bond purchases, financed by the issuance of\n",
    "central bank reserves, at £10 billion. The Committee also voted unanimously to maintain\n",
    "the stock of UK government bond purchases, financed by the issuance of central bank\n",
    "reserves, at £435 billion.\"\"\",\n",
    "\"\"\"Potential supply growth remains subdued over the forecast period (Section 4). Labour supply growth is modest.\n",
    "Productivity growth is weak in the first part of the forecast period. Further out, it picks up somewhat as some of the\n",
    "effects of Brexit-related factors fade. Taken together, potential supply growth averages 1% per year over the forecast\n",
    "period (Table 1.B).\n",
    "\"\"\",\n",
    "\"\"\"Monetary policy will be set to ensure a sustainable return of inflation to the 2% target. Policy may need to reinforce\n",
    "the expected recovery in UK GDP growth should the more positive signals from recent indicators of global and\n",
    "domestic activity not be sustained or should indicators of domestic prices remain relatively weak. Further ahead, if the\n",
    "economy recovers broadly in line with the MPC’s latest projections, some modest tightening of policy may be needed\n",
    "to maintain inflation sustainably at the target.\n",
    "The MPC judges at this meeting that the existing stance of monetary policy is appropriate.\n",
    "\"\"\",\n",
    "\"\"\"Lorem Ipsum Dolor Sit Amet\n",
    "\"\"\",\n",
    "\"\"\"The quick brown fox jumps over the lazy dog\n",
    "\"\"\",\n",
    "\"\"\"chodzy jerzy kolo wiezy i nie wierzy ze na wiezy jest trzydzieści jerzy\n",
    "\"\"\"\n",
    "]\n",
    "\n",
    "passages_embeddings = model.encode(passages, normalize_embeddings=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32255208"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(passages_embeddings[0].reshape(1,-1), passages_embeddings[-1].reshape(1,-1))[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading item: adj_matrix\n",
      "Loading item: adj_vectors\n",
      "Loading item: edge_thresh\n",
      "Loading item: embedded_index\n"
     ]
    }
   ],
   "source": [
    "from StructuredRag.algorithms.inquirer import StructRAGInquirer\n",
    "\n",
    "inquirer = StructRAGInquirer(\n",
    "    path_to_experiment='../results/v3/2024-06-16',\n",
    "    llm_name='google/flan-t5-large',\n",
    "    llm_max_tokens=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 3.0.0.dev0, however, your version is 3.0.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n",
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Adding edges to graph: 100%|██████████| 3914/3914 [00:01<00:00, 3699.04it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (808 > 512). Running this sequence through the model will result in indexing errors\n",
      "c:\\Miniconda3\\envs\\diss_rag\\lib\\site-packages\\transformers\\generation\\utils.py:1283: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "res = inquirer.run_inquirer(\n",
    "    query='How will climate change affect the economy?',\n",
    "    # source_document_name='MPR November 2023.pdf',\n",
    "    source_document_name='monetary-policy-report-may-2020.pdf',\n",
    "    k_context=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'Covid-19 affects economic activity through a series of channels',\n",
       " 'input_documents': [Document(page_content='slack Weaker world activit yAmpliﬁers:• Uncertainty• Conﬁdenc e\\n• Credit conditions• Financial  \\ncondition s\\nRetrenchment by corpor ates:\\n• Lower investment\\n• Worker lay-offs• Capital scrapping• Bankruptcies• Fewer ﬁrm entries\\nLower export demandInﬂation (differential price \\neffects across sectors )\\nExternal cost pressures:• Exchange rate• Commodity prices• World export price sChanges in demand\\nChanges in supplyPolicy action from governments and central banks  to ease \\nseverity of the downturn  \\nand limit long-term \\ndamage to the econom yFigure 1 Covid-19 affects economic activity through a series of channels', metadata={'doc_num': 1, 'doc_description': 'The Bank has published its quarterly Monetary Policy Report alongside an interim Financial Stability Report. Together, they provide a scenario for the path of the UK economy in the light of Covid-19 and assess the financial system’s resilience to that scenario.', 'doc_date': '2020-07-04 00:00:00', 'doc_difference': 0, 'title': 'monetary-policy-report-may-2020.pdf'}),\n",
       "  Document(page_content='Monetary Policy Report November 2019  Annex Other forecasters’ expectations   44\\nAnnex\\nOther forecasters’ expectations\\nThis annex reports the results of the Bank’s most recent survey of external forecasters, carried out in October.  \\nThe results of this survey are summarised in Table 1. (1) \\nOn average, respondents expected four-quarter GDP growth to pick up slightly over the next three years to 1.7% in \\n2022 Q4. That is lower than the November Report forecast (Chart A).\\nTable 1 Averages of other forecasters’ central projections\\n 2020 Q4 2021 Q4 2022 Q4\\nCPI inflation(a) 1.9 1.9 2.0\\nGDP growth(b) 1.4 1.6 1.7\\nLFS unemployment rate (per cent) 4.1 4.2 4.3\\nBank Rate (per cent) 0.8 1.0 1.4\\nStock of purchased gilts (£ billions)(c) 441 441 442\\nStock of purchased corporate bonds (£ billions)(c) 9 11 11\\nSterling', metadata={'doc_num': 3, 'doc_description': 'Our quarterly Monetary Policy Report sets out the economic analysis and inflation projections that the Monetary Policy Committee uses to make its interest rate decisions.', 'doc_date': '2019-07-11 00:00:00', 'doc_difference': 2.248093030327946, 'title': 'monetary-policy-report-november-2019.pdf'}),\n",
       "  Document(page_content='2%–3%. However, some contacts reported giving larger increases to address skill shortages or to keep pace with the National Living Wage. \\nAgents’ survey on preparations for EU withdrawal \\nThe Agents surveyed over 300 business contacts on their preparations for EU withdrawal. (3)\\nAlmost all respondents said they were either ‘fully ready’ or ‘as ready as can be’ for a no-deal Brexit, up from around four fifths of respondents in the September survey (Chart A).\\n(1) A comprehensive quarterly report on business conditions from the Agents is published alongside the MPC decision in non- Monetary Policy Report months. The next \\nreport will be published on 19  December  2019.\\n(2) This is a summary of economic reports compiled by the Agents during September and October  2019. References to activity and prices relate to the past three months \\ncompared with a year earlier. The Agents’ scores are available here.\\n(3) The survey was conducted between 5  September and 15  October. There were 341 r esponses from companies employing around 316,000 employees. Responses were \\nweighted by employment and then reweighted by sector employment.0102030405060708090100\\nJan. Mar. Apr.', metadata={'doc_num': 2, 'doc_description': 'Our quarterly Monetary Policy Report sets out the economic analysis and inflation projections that the Monetary Policy Committee uses to make its interest rate decisions.', 'doc_date': '2019-07-11 00:00:00', 'doc_difference': 2.2846305476356776, 'title': 'monetary-policy-report-november-2019.pdf'})]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.24579640986078943\n",
      "0.25843880294410515\n"
     ]
    }
   ],
   "source": [
    "for doc in res['input_documents']:\n",
    "    print(doc.metadata[\"doc_difference\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legacy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load some required data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment: v0\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "     || Run: 2024-05-25\n",
      "Experiment: v1\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v3\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v4\n",
      "     || Run: 2024-05-10\n",
      "     || Run: 2024-05-14\n",
      "Experiment: v5\n",
      "     || Run: 2024-05-14\n"
     ]
    }
   ],
   "source": [
    "# Select the runs you want to load\n",
    "for experiment in sorted(os.listdir('../results')):\n",
    "    print('Experiment:', experiment)\n",
    "    for run in sorted(os.listdir('../results/' + experiment)):\n",
    "        print(\"     || Run:\", run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading item: embedded_index\n",
      "Loading item: edge_thresh\n",
      "Loading item: adj_matrix\n"
     ]
    }
   ],
   "source": [
    "run_path = 'v0/2024-05-25'\n",
    "\n",
    "data = {}\n",
    "# Read the data for the specified experiment\n",
    "for item in os.listdir('../results/' + run_path):\n",
    "    print('Loading item:', item.split('.')[0])\n",
    "    \n",
    "    with open('../results/' + run_path + '/' + item, 'rb') as f:\n",
    "        data[item.split('.')[0]] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the query and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'monetary policy report february 2024.pdf'\n",
      "'.gitkeep'\n",
      "'MPR November 2023.pdf'\n"
     ]
    }
   ],
   "source": [
    "# User selects one of the documents\n",
    "for doc in os.listdir(\"../data/01_raw/\"):\n",
    "    pprint(doc)\n",
    "\n",
    "selected_doc = 'monetary policy report february 2024.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "# User's query\n",
    "# query = 'What is the relationship between unemployment and inflation?'\n",
    "query = 'What are the key risks to the economy'\n",
    "\n",
    "# Embed the query\n",
    "embedded_query = embedding_funcs.embed_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the most similar chunk of the document\n",
    "sim_scores = {}\n",
    "for doc in data['embedded_index']:\n",
    "    if doc.metadata[\"file_name\"].split(\"/\")[-1] == selected_doc:\n",
    "        sim_scores[doc.id_] = float(util.dot_score(embedded_query, doc.embedding))\n",
    "        # sim_scores[doc.id_] = cosine_similarity(embedded_query.reshape(1, -1), np.array(doc.embedding).reshape(1, -1))[0][0]\n",
    "\n",
    "# Sort the chunks\n",
    "doc_similarity = dict(sorted(sim_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "\n",
    "most_similar_doc_id = list(doc_similarity.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Inspect the performance of the embedding search\n",
    "# for doc in data['embedded_index']:\n",
    "#     if doc.id_ == most_similar_doc_id:\n",
    "#         print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search through the graph to find the most similar nodes\n",
    "graph = graph_construction.construct_graph_from_adj_dict(data['adj_matrix'], data['edge_thresh'], data['embedded_index'])\n",
    "\n",
    "node_paths = nx.single_source_dijkstra(G=graph, source=most_similar_doc_id, weight='weight')\n",
    "\n",
    "k = 5\n",
    "nearest_node_ids = list(node_paths[0].items())[:k]\n",
    "# nearest_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('28366e53-34b9-4492-a96f-c780adaa8911', 0),\n",
       " ('b3b0668a-275d-425d-b5ee-a7f3921e1fa8', 0.24459935597241614),\n",
       " ('f6245d2a-e66c-4346-a7d3-5a3fc098c453', 0.28790442749836603),\n",
       " ('6607baa7-b597-41c1-81c9-8c229f0cb397', 0.2928786271924973),\n",
       " ('6e008375-ac01-4a8d-b71e-30a17715d2b2', 0.3375807858294453)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_node_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the info from the nodes\n",
    "nearest_docs = []\n",
    "for doc in data['embedded_index']:\n",
    "    for node in nearest_node_ids:\n",
    "        if node[0] == doc.id_:\n",
    "            nearest_docs.append((doc, node[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nearest_docs[3][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "generative_model_name = \"google/flan-t5-large\"\n",
    "llm_temperature = 0.0\n",
    "llm_max_tokens = 512\n",
    "\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=generative_model_name, \n",
    "    task=\"text2text-generation\", \n",
    "    model_kwargs={\n",
    "        # \"temperature\": llm_temperature, \n",
    "        \"max_length\": llm_max_tokens,\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the documents into a langchain document class\n",
    "top_matches = [\n",
    "    Document(\n",
    "        page_content=doc.text,\n",
    "        metadata={\n",
    "            'doc_num': i + 1,\n",
    "            # **doc.metadata,\n",
    "        }\n",
    "    )\n",
    "    for i, doc in enumerate(nearest_docs)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pydantic import BaseModel, Field\n",
    "# from typing import List, Optional\n",
    "\n",
    "\n",
    "# class LlmResponse(BaseModel):\n",
    "#     answer_provided: bool = Field(\n",
    "#         description=\"\"\"True if enough information is provided in the context to answer\n",
    "#         the question, False otherwise.\"\"\"\n",
    "#     )\n",
    "#     most_likely_answer: Optional[str] = Field(\n",
    "#         description=\"\"\"Answer to the question, quoting or only minimally rephrasing\n",
    "#         the provided text. Empty if answer_provided=False.\"\"\"\n",
    "#     )\n",
    "#     highlighting1: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the first context document,\n",
    "#         that are most relevant to the question and should therefore be highlighted\n",
    "#         within the context.\"\"\"\n",
    "#     )\n",
    "#     highlighting2: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the second context document,\n",
    "#         that are most relevant to the question and should therefore be highlighted\n",
    "#         within the context.\"\"\"\n",
    "#     )\n",
    "#     highlighting3: List[str] = Field(\n",
    "#         description=\"\"\"List of short exact subphrases from the third and any further\n",
    "#         context document, that are most relevant to the question and should therefore\n",
    "#         be highlighted within the context.\n",
    "#         Empty if the number of context documents is smaller.\"\"\"\n",
    "#     )\n",
    "#     reasoning: Optional[str] = Field(\n",
    "#         description=\"\"\"Step by step reasoning why an answer has been selected or could\n",
    "#         not be provided. Reasoning how highlighted keywords relate to the question.\"\"\"\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "_core_prompt = \"\"\"\n",
    "==Background==\n",
    "You are an AI assistant with a focus on helping to answer economists' search questions\n",
    "over particular documents. Your responses should be based only\n",
    "on information provided within the query. It is important to maintain impartiality\n",
    "and non-partisanship. If you are unable to answer a question based on the given\n",
    "instructions, please indicate so. Your responses should be concise and professional,\n",
    "using British English.\n",
    "Consider the current date, {current_datetime}, when providing responses related to time. \n",
    "\"\"\"\n",
    "\n",
    "_extractive_prompt = \"\"\"\n",
    "==TASK==\n",
    "Your task is to extract and write an answer for the question based on the provided\n",
    "contexts. Make sure to quote a part of the provided context closely. If the question\n",
    "cannot be answered from the information in the context, please do not provide an answer.\n",
    "If the context is not related to the question, please do not provide an answer.\n",
    "Most importantly, even if no answer is provided, find one to three short phrases\n",
    "or keywords in each context that are most relevant to the question, and return them\n",
    "separately as exact quotes (using the exact verbatim text and punctuation).\n",
    "Explain your reasoning.\n",
    "\n",
    "Question: {question}\n",
    "Contexts: {summaries}\n",
    "\"\"\"\n",
    "\n",
    "# parser = PydanticOutputParser(pydantic_object=LlmResponse)\n",
    "\n",
    "EXTRACTIVE_PROMPT_PYDANTIC = PromptTemplate.from_template(\n",
    "    template=_core_prompt\n",
    "    + _extractive_prompt,\n",
    "    # + \"\\n\\n ==RESPONSE FORMAT==\\n{format_instructions}\"\n",
    "    # + \"\\n\\n ==JSON RESPONSE ==\\n\",\n",
    "    partial_variables={\n",
    "        \"current_datetime\": str(date.today()),\n",
    "        # \"format_instructions\": parser.get_format_instructions(),\n",
    "    },\n",
    ")\n",
    "\n",
    "_stuff_document_template = (\n",
    "    \"<Doc{doc_num} >{page_content}</Doc{doc_num}>\"\n",
    ")\n",
    "\n",
    "STUFF_DOCUMENT_PROMPT = PromptTemplate.from_template(_stuff_document_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stuff the documents into the model\n",
    "chain = load_qa_with_sources_chain(\n",
    "    llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=EXTRACTIVE_PROMPT_PYDANTIC,\n",
    "    document_prompt=STUFF_DOCUMENT_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2698 > 512). Running this sequence through the model will result in indexing errors\n",
      "/Users/lukasalemu/Downloads/ls/envs/dissertation_rag/lib/python3.10/site-packages/transformers/generation/utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\"input_documents\": top_matches, \"question\": query},\n",
    "    return_only_outputs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_text': 'There are risks in both directions around the central projections for domestic spending and GDP , including those related to the transmission of monetary policy. In particular, there is uncertainty around the collateral and precautionary savings channels through which house prices af fect consumer spending, and around the extent to which the full effects of interest rates on business.'}"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diss_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
